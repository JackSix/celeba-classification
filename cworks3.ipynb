{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-06T23:13:00.649545Z",
     "start_time": "2018-03-06T23:12:57.808848Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# import modules\n",
    "\"\"\"\n",
    "Created on Tue Feb 20 15:10:00 2018\n",
    "\n",
    "@author: Yacalis\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "from Callbacks import Callbacks\n",
    "from Config import Config\n",
    "from DataLoader import retrieve_data\n",
    "from folder_defs import get_log_dir, get_data_dir, get_train_dir, get_test_dir\n",
    "from train_model import train_model\n",
    "from build_model import build_model\n",
    "from save_model import save_model\n",
    "from get_data_dict import get_data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-06T23:13:00.660195Z",
     "start_time": "2018-03-06T23:13:00.653025Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning program\n"
     ]
    }
   ],
   "source": [
    "print('Beginning program')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-06T23:13:00.682578Z",
     "start_time": "2018-03-06T23:13:00.664007Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unparsed config options: ['-f', '/Users/Yacalis/Library/Jupyter/runtime/kernel-4b96d059-124e-41da-ad50-f2f0fb96722c.json']\n",
      "change lr: True\n",
      "change bs: False\n",
      "max epochs: 20\n"
     ]
    }
   ],
   "source": [
    "# get config\n",
    "config = Config().config\n",
    "print('change lr:', config.change_lr)\n",
    "print('change bs:', config.change_bs)\n",
    "print('max epochs:', config.epochs)\n",
    "if config.change_bs == config.change_lr:\n",
    "    print(f'[!] Whoops: config.change_bs and config.change_lr should be '\n",
    "          f'different bool values, but they are both {config.change_bs} '\n",
    "          f'-- please set one and only one of them to True')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-06T23:13:00.705957Z",
     "start_time": "2018-03-06T23:13:00.687366Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log dir: /Users/Yacalis/Projects/TensorFlow/cs274c-data/logs/0306_151300-changelr_True-changebs_False-batch_4\n",
      "data dir: /Users/Yacalis/Projects/TensorFlow/cs274c-data/\n",
      "train dir: /Users/Yacalis/Projects/TensorFlow/cs274c-data/test_images/train/\n",
      "test dir: /Users/Yacalis/Projects/TensorFlow/cs274c-data/test_images/val/\n"
     ]
    }
   ],
   "source": [
    "# get directories\n",
    "log_dir = get_log_dir(config)\n",
    "data_dir = get_data_dir()\n",
    "train_dir = get_train_dir()\n",
    "test_dir = get_test_dir()\n",
    "print('log dir:', log_dir)\n",
    "print('data dir:', data_dir)\n",
    "print('train dir:', train_dir)\n",
    "print('test dir:', test_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-06T23:13:42.928239Z",
     "start_time": "2018-03-06T23:13:00.710924Z"
    },
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "data file:  /Users/Yacalis/Projects/TensorFlow/cs274c-data/imdb.mat\n",
      "number of records from data file:  460723\n",
      "image dir:  /Users/Yacalis/Projects/TensorFlow/cs274c-data/test_images/train/\n",
      "\tsub dirs:\n",
      "\t\t 00\n",
      "\t\t 01\n",
      "\t\t 02\n",
      "\t\t 03\n",
      "\t\t 04\n",
      "\t\t 05\n",
      "shape of x_data:  (4229, 228, 228, 3)\n",
      "Num training examples (excludes test and val): 3383\n"
     ]
    }
   ],
   "source": [
    "# get data\n",
    "print('Loading data...')\n",
    "data_dict = get_data_dict(data_dir)\n",
    "x_data, y_data = retrieve_data(data_dict=data_dict, image_dir=train_dir)\n",
    "num_train = int(x_data.shape[0] * 0.8)\n",
    "print(f'Num training examples (excludes test and val): {num_train}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-06T23:13:45.304040Z",
     "start_time": "2018-03-06T23:13:42.931788Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building model...\n",
      "Finished building model\n",
      "Compiling model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 56, 56, 96)        14208     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 27, 27, 96)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 27, 27, 96)        384       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 23, 23, 256)       614656    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 11, 11, 256)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 11, 11, 256)       1024      \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 9, 9, 384)         885120    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 4, 4, 384)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 4, 4, 384)         1536      \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 6144)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               3146240   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 2)                 1026      \n",
      "=================================================================\n",
      "Total params: 4,926,850\n",
      "Trainable params: 4,925,378\n",
      "Non-trainable params: 1,472\n",
      "_________________________________________________________________\n",
      "Finished compiling\n",
      "Saving model...\n",
      "Model saved\n"
     ]
    }
   ],
   "source": [
    "# build and save initial model\n",
    "input_dim = x_data[0].shape\n",
    "model = build_model(input_dim, config)\n",
    "save_model(log_dir=log_dir, config=config, model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-06T23:13:45.323128Z",
     "start_time": "2018-03-06T23:13:45.307619Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# set variables\n",
    "val_loss = []\n",
    "val_acc = []\n",
    "loss = []\n",
    "acc = []\n",
    "lr = []\n",
    "bs = []\n",
    "max_epochs = config.epochs\n",
    "batch_size = config.batch_size\n",
    "batch_size_mult = 2\n",
    "epoch_iter = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-06T23:13:49.153831Z",
     "start_time": "2018-03-06T23:13:45.328025Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "callbacks:\n",
      "\t <keras.callbacks.TensorBoard object at 0x11dc7def0>\n",
      "\t <keras.callbacks.ModelCheckpoint object at 0x10e5b0d30>\n",
      "\t <keras.callbacks.History object at 0x11eebaa58>\n",
      "\t <keras.callbacks.ReduceLROnPlateau object at 0x10e5b02e8>\n"
     ]
    }
   ],
   "source": [
    "# get callbacks\n",
    "callbacks = Callbacks(config, log_dir).callbacks\n",
    "print('callbacks:')\n",
    "for callback in callbacks:\n",
    "    print('\\t', callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-03-06T23:12:57.828Z"
    },
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Will reduce learning rate during training, but not batch size\n",
      "Training model...\n",
      "Train on 3383 samples, validate on 846 samples\n",
      "Epoch 1/20\n",
      "3383/3383 [==============================] - 369s 109ms/step - loss: 6.6812 - acc: 0.5723 - val_loss: 7.0874 - val_acc: 0.5603\n",
      "Epoch 2/20\n",
      "3383/3383 [==============================] - 379s 112ms/step - loss: 6.8109 - acc: 0.5770 - val_loss: 7.0874 - val_acc: 0.5603\n",
      "Epoch 3/20\n",
      "3383/3383 [==============================] - 397s 117ms/step - loss: 6.7941 - acc: 0.5785 - val_loss: 7.0874 - val_acc: 0.5603\n",
      "Epoch 4/20\n",
      "3383/3383 [==============================] - 401s 119ms/step - loss: 6.7941 - acc: 0.5785 - val_loss: 7.0874 - val_acc: 0.5603\n",
      "Epoch 5/20\n",
      "3383/3383 [==============================] - 369s 109ms/step - loss: 6.7941 - acc: 0.5785 - val_loss: 7.0874 - val_acc: 0.5603\n",
      "Epoch 6/20\n",
      "3383/3383 [==============================] - 384s 113ms/step - loss: 6.7941 - acc: 0.5785 - val_loss: 7.0874 - val_acc: 0.5603\n",
      "\n",
      "Epoch 00006: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 7/20\n",
      "3383/3383 [==============================] - 385s 114ms/step - loss: 6.7941 - acc: 0.5785 - val_loss: 7.0874 - val_acc: 0.5603\n",
      "Epoch 8/20\n",
      "3383/3383 [==============================] - 391s 116ms/step - loss: 6.7941 - acc: 0.5785 - val_loss: 7.0874 - val_acc: 0.5603\n",
      "Epoch 9/20\n",
      "3383/3383 [==============================] - 418s 124ms/step - loss: 6.7941 - acc: 0.5785 - val_loss: 7.0874 - val_acc: 0.5603\n",
      "Epoch 10/20\n",
      "3383/3383 [==============================] - 393s 116ms/step - loss: 6.7941 - acc: 0.5785 - val_loss: 7.0874 - val_acc: 0.5603\n",
      "\n",
      "Epoch 00010: saving model to /Users/Yacalis/Projects/TensorFlow/cs274c-data/logs/0306_151300-changelr_True-changebs_False-batch_4/chckpt.ep_10-loss_7.09.hdf5\n",
      "\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 11/20\n",
      "3383/3383 [==============================] - 422s 125ms/step - loss: 6.7941 - acc: 0.5785 - val_loss: 7.0874 - val_acc: 0.5603\n",
      "Epoch 12/20\n",
      "3383/3383 [==============================] - 432s 128ms/step - loss: 6.7941 - acc: 0.5785 - val_loss: 7.0874 - val_acc: 0.5603\n",
      "Epoch 13/20\n",
      "3383/3383 [==============================] - 412s 122ms/step - loss: 6.7941 - acc: 0.5785 - val_loss: 7.0874 - val_acc: 0.5603\n",
      "Epoch 14/20\n",
      "3383/3383 [==============================] - 404s 119ms/step - loss: 6.7941 - acc: 0.5785 - val_loss: 7.0874 - val_acc: 0.5603\n",
      "\n",
      "Epoch 00014: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 15/20\n",
      " 108/3383 [..............................] - ETA: 5:37 - loss: 6.5666 - acc: 0.5926"
     ]
    }
   ],
   "source": [
    "# train model\n",
    "if config.change_lr:  # reduce_lr callback takes care of everything for us\n",
    "    print('Will reduce learning rate during training, but not batch size')\n",
    "    print('Training model...')\n",
    "    model, history = train_model(model, x_data, y_data, batch_size, max_epochs, callbacks)\n",
    "\n",
    "    # store history (bs is constant)\n",
    "    val_loss += history.history['val_loss']\n",
    "    val_acc += history.history['val_acc']\n",
    "    loss += history.history['loss']\n",
    "    acc += history.history['acc']\n",
    "    lr += history.history['lr']\n",
    "    bs = [batch_size for i in range(len(lr))]\n",
    "\n",
    "elif config.change_bs:  # need to manually stop and restart training\n",
    "    print('Will reduce batch size during training, but not learning rate')\n",
    "    while max_epochs >= epoch_iter:\n",
    "        print(f'Currently at epoch {epoch_iter} of {max_epochs}, batch size is {batch_size}')\n",
    "        epochs = max_epochs - epoch_iter + 1\n",
    "        model, history = train_model(model, x_data, y_data, batch_size, epochs, callbacks)\n",
    "\n",
    "        # store history\n",
    "        val_loss += history.history['val_loss']\n",
    "        val_acc += history.history['val_acc']\n",
    "        loss += history.history['loss']\n",
    "        acc += history.history['acc']\n",
    "        bs += [batch_size for i in range(len(history.epoch))]\n",
    "\n",
    "        # update training parameters\n",
    "        epoch_iter += len(history.epoch)\n",
    "        batch_size *= batch_size_mult\n",
    "        batch_size = batch_size if batch_size < num_train else num_train\n",
    "\n",
    "    # store lr history as constant\n",
    "    lr = [0.001 for i in range(len(bs))]\n",
    "\n",
    "else:  # this should never happen\n",
    "    print(f'[!] Whoops: config.change_bs and config.change_lr are both '\n",
    "          f'set to False - please set one of them to True')\n",
    "\n",
    "print('Completed training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-03-06T23:12:57.830Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# save finished model\n",
    "save_model(log_dir=log_dir, config=config, model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-03-06T23:12:57.833Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# save loss, accuracy, lr, and bs values across epochs as json\n",
    "acc_loss_lr_bs = {'val_loss': val_loss,\n",
    "                  'val_acc': val_acc,\n",
    "                  'loss': loss,\n",
    "                  'acc': acc,\n",
    "                  'lr': [np.float64(i) for i in lr],\n",
    "                  'bs': bs\n",
    "                  }\n",
    "acc_loss_lr_bs_path = os.path.join(log_dir, 'acc_loss_lr_bs.json')\n",
    "with open(acc_loss_lr_bs_path, 'w') as f:\n",
    "    json.dump(acc_loss_lr_bs, f, indent=4, sort_keys=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-03-06T23:12:57.835Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# evaluate model\n",
    "print('Calculating final score...')\n",
    "x_data, y_data = retrieve_data(data_dict=data_dict, image_dir=test_dir)\n",
    "score = model.evaluate(x_data, y_data, batch_size=batch_size)\n",
    "print('Final score:', score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-03-06T23:12:57.839Z"
    }
   },
   "outputs": [],
   "source": [
    "print('Completed program')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-03-06T23:12:57.842Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# PLOTTING FOR TESTING\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-03-06T23:12:57.845Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# load dict from json\n",
    "d = None\n",
    "with open(acc_loss_lr_bs_path, 'r') as f:\n",
    "    d = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-03-06T23:12:57.847Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# plot dict values\n",
    "plt.figure(figsize=(20,10))\n",
    "\n",
    "# summarize history for accuracy\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.plot(d['acc'])\n",
    "plt.plot(d['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "\n",
    "# summarize history for loss\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.plot(d['loss'])\n",
    "plt.plot(d['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "\n",
    "# summarize history for lr\n",
    "plt.subplot(2, 2, 3)\n",
    "plt.plot(d['lr'])\n",
    "plt.title('model lr')\n",
    "plt.ylabel('lr')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['lr'], loc='upper left')\n",
    "\n",
    "# summarize history for bs\n",
    "plt.subplot(2, 2, 4)\n",
    "plt.plot(d['bs'])\n",
    "plt.title('model bs')\n",
    "plt.ylabel('bs')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['bs'], loc='upper left')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
